/**
 * Performance Benchmarks for Transport Layer
 *
 * Validates MessagePort transport implementation performance:
 * 1. Throughput: Pack transfer >1MB/sec for 10MB+ packfiles
 * 2. Latency: Ref discovery + negotiation <100ms
 * 3. Memory: Heap overhead <50MB during large transfers
 * 4. Concurrency: 10 concurrent operations scale linearly
 */

import { randomFillSync } from "node:crypto";
import type { HistoryWithOperations, PersonIdent } from "@statewalker/vcs-core";
import { createMemoryHistoryWithOperations } from "@statewalker/vcs-core";
import { describe, expect, it } from "vitest";
import { messagePortFetch } from "../src/adapters/messageport/messageport-fetch.js";
import { messagePortServe } from "../src/adapters/messageport/messageport-serve.js";
import type {
  ExportPackOptions,
  PackImportResult,
  RepositoryFacade,
} from "../src/api/repository-facade.js";
import type { RefStore } from "../src/context/process-context.js";

// ─────────────────────────────────────────────────────────────────────────────
// Adapters: Bridge History → Transport interfaces
// ─────────────────────────────────────────────────────────────────────────────

function createRefStoreAdapter(history: HistoryWithOperations): RefStore {
  return {
    async get(name: string): Promise<string | undefined> {
      const ref = await history.refs.resolve(name);
      if (!ref) return undefined;
      if ("objectId" in ref) return ref.objectId;
      return undefined;
    },
    async update(name: string, oid: string): Promise<void> {
      await history.refs.set(name, oid);
    },
    async listAll(): Promise<Iterable<[string, string]>> {
      const result: [string, string][] = [];
      for await (const ref of history.refs.list()) {
        if ("objectId" in ref && ref.objectId) {
          result.push([ref.name, ref.objectId]);
        }
      }
      return result;
    },
    async getSymrefTarget(name: string): Promise<string | undefined> {
      const ref = await history.refs.resolve(name);
      if (ref && "target" in ref) return (ref as { target: string }).target;
      return undefined;
    },
    async isRefTip(oid: string): Promise<boolean> {
      for await (const ref of history.refs.list()) {
        if ("objectId" in ref && ref.objectId === oid) return true;
      }
      return false;
    },
  };
}

function createRepoFacade(history: HistoryWithOperations): RepositoryFacade {
  return {
    async importPack(packStream: AsyncIterable<Uint8Array>): Promise<PackImportResult> {
      return history.serialization.importPack(packStream);
    },
    async *exportPack(
      wants: Set<string>,
      exclude: Set<string>,
      _options?: ExportPackOptions,
    ): AsyncIterable<Uint8Array> {
      const objectIds = history.collectReachableObjects(wants, exclude);
      yield* history.serialization.createPack(objectIds);
    },
    async has(oid: string): Promise<boolean> {
      if (await history.commits.has(oid)) return true;
      if (await history.trees.has(oid)) return true;
      if (await history.blobs.has(oid)) return true;
      if (await history.tags.has(oid)) return true;
      return false;
    },
    async *walkAncestors(startOid: string): AsyncGenerator<string> {
      const visited = new Set<string>();
      const queue: string[] = [startOid];
      while (queue.length > 0) {
        const oid = queue.shift();
        if (!oid || visited.has(oid)) continue;
        visited.add(oid);
        const commit = await history.commits.load(oid);
        if (commit) {
          yield oid;
          for (const parentOid of commit.parents) {
            if (!visited.has(parentOid)) queue.push(parentOid);
          }
        }
      }
    },
  };
}

// ─────────────────────────────────────────────────────────────────────────────
// Test Data Helpers
// ─────────────────────────────────────────────────────────────────────────────

function createPerson(index: number): PersonIdent {
  return {
    name: "Benchmark Author",
    email: "bench@example.com",
    timestamp: 1700000000 + index * 60,
    tzOffset: "+0000",
  };
}

/** Create random content that resists zlib compression. */
function createRandomContent(size: number): Uint8Array {
  const data = new Uint8Array(size);
  randomFillSync(data);
  return data;
}

/** Create a commit with a blob of the given size. */
async function createCommitWithBlob(
  history: HistoryWithOperations,
  blobSize: number,
  index: number,
  parent?: string,
): Promise<string> {
  const content = createRandomContent(blobSize);
  const blobId = await history.blobs.store([content]);
  const treeId = await history.trees.store([
    { mode: 0o100644, name: `data-${index}.bin`, id: blobId },
  ]);
  return history.commits.store({
    tree: treeId,
    parents: parent ? [parent] : [],
    author: createPerson(index),
    committer: createPerson(index),
    message: `Benchmark commit ${index}`,
  });
}

/** Create a chain of commits with large blobs, return tip OID. */
async function createLargeRepo(
  history: HistoryWithOperations,
  commitCount: number,
  blobSize: number,
): Promise<string> {
  let parent: string | undefined;
  for (let i = 0; i < commitCount; i++) {
    parent = await createCommitWithBlob(history, blobSize, i, parent);
  }
  await history.refs.set("refs/heads/main", parent!);
  return parent!;
}

/** Collect all chunks from an async iterable into a single Uint8Array. */
async function collectBytes(stream: AsyncIterable<Uint8Array>): Promise<Uint8Array> {
  const chunks: Uint8Array[] = [];
  for await (const chunk of stream) {
    chunks.push(chunk);
  }
  const total = chunks.reduce((sum, c) => sum + c.length, 0);
  const result = new Uint8Array(total);
  let offset = 0;
  for (const chunk of chunks) {
    result.set(chunk, offset);
    offset += chunk.length;
  }
  return result;
}

async function* toAsyncIterable(data: Uint8Array): AsyncIterable<Uint8Array> {
  yield data;
}

function formatBytes(bytes: number): string {
  if (bytes >= 1024 * 1024) return `${(bytes / (1024 * 1024)).toFixed(2)} MB`;
  if (bytes >= 1024) return `${(bytes / 1024).toFixed(2)} KB`;
  return `${bytes} B`;
}

function formatRate(bytesPerSec: number): string {
  return `${(bytesPerSec / (1024 * 1024)).toFixed(2)} MB/s`;
}

// ─────────────────────────────────────────────────────────────────────────────
// 1. Throughput Benchmarks
// ─────────────────────────────────────────────────────────────────────────────

describe("Performance Benchmarks", () => {
  describe("1. Throughput", () => {
    it("pack creation + import >1MB/sec for 10MB+ data", { timeout: 60000 }, async () => {
      // Create server repo with ~10MB+ of blob data (55 commits × 200KB blobs)
      const server = createMemoryHistoryWithOperations();
      await server.initialize();

      const tipId = await createLargeRepo(server, 55, 200 * 1024);

      // Create pack from server objects
      const packStart = performance.now();
      const objects = server.collectReachableObjects(new Set([tipId]), new Set());
      const packBytes = await collectBytes(server.serialization.createPack(objects));
      const packDuration = performance.now() - packStart;

      console.log(`\n[THROUGHPUT] Pack creation:`);
      console.log(`  Pack size: ${formatBytes(packBytes.length)}`);
      console.log(`  Duration: ${packDuration.toFixed(2)}ms`);
      console.log(`  Rate: ${formatRate((packBytes.length / packDuration) * 1000)}`);

      // Import pack into fresh client repo
      const client = createMemoryHistoryWithOperations();
      await client.initialize();

      const importStart = performance.now();
      const result = await client.serialization.importPack(toAsyncIterable(packBytes));
      const importDuration = performance.now() - importStart;

      console.log(`\n[THROUGHPUT] Pack import:`);
      console.log(`  Objects imported: ${result.objectsImported}`);
      console.log(`  Duration: ${importDuration.toFixed(2)}ms`);
      console.log(`  Rate: ${formatRate((packBytes.length / importDuration) * 1000)}`);

      const totalDuration = packDuration + importDuration;
      const throughput = (packBytes.length / totalDuration) * 1000;

      console.log(`\n[THROUGHPUT] Combined (creation + import):`);
      console.log(`  Total duration: ${totalDuration.toFixed(2)}ms`);
      console.log(`  Effective throughput: ${formatRate(throughput)}`);

      // Validate: >1MB/sec
      expect(throughput).toBeGreaterThan(1024 * 1024);
      expect(packBytes.length).toBeGreaterThan(10 * 1024 * 1024); // >10MB pack
      expect(result.commitsImported).toBe(55);

      await client.close();
      await server.close();
    });

    it("MessagePort duplex raw throughput >10MB/sec", { timeout: 30000 }, async () => {
      const channel = new MessageChannel();
      const { createMessagePortDuplex } = await import(
        "../src/adapters/messageport/messageport-duplex.js"
      );

      const duplex1 = createMessagePortDuplex(channel.port1);
      const duplex2 = createMessagePortDuplex(channel.port2);

      const totalSize = 10 * 1024 * 1024; // 10MB
      const chunkSize = 64 * 1024; // 64KB chunks
      const chunkCount = Math.ceil(totalSize / chunkSize);

      const receivedChunks: Uint8Array[] = [];
      const receivePromise = (async () => {
        for await (const chunk of duplex2) {
          receivedChunks.push(chunk);
          if (receivedChunks.length >= chunkCount) break;
        }
      })();

      const sendStart = performance.now();

      // Send chunks
      for (let i = 0; i < chunkCount; i++) {
        duplex1.write(createRandomContent(chunkSize));
      }

      await receivePromise;
      const duration = performance.now() - sendStart;

      const totalReceived = receivedChunks.reduce((sum, c) => sum + c.length, 0);
      const throughput = (totalReceived / duration) * 1000;

      console.log(`\n[DUPLEX THROUGHPUT] MessagePort raw transfer:`);
      console.log(`  Data transferred: ${formatBytes(totalReceived)}`);
      console.log(`  Chunks: ${receivedChunks.length}`);
      console.log(`  Duration: ${duration.toFixed(2)}ms`);
      console.log(`  Throughput: ${formatRate(throughput)}`);

      expect(totalReceived).toBe(totalSize);
      expect(throughput).toBeGreaterThan(10 * 1024 * 1024); // >10MB/sec

      await duplex1.close();
      channel.port1.close();
      channel.port2.close();
    });

    it("end-to-end MessagePort fetch transfers pack at >1MB/sec", { timeout: 60000 }, async () => {
      // Server repo with ~4MB of data (40 commits × 100KB blobs)
      const server = createMemoryHistoryWithOperations();
      await server.initialize();
      const tipId = await createLargeRepo(server, 40, 100 * 1024);

      // Measure pack size for throughput calculation
      const packBytes = await collectBytes(
        server.serialization.createPack(
          server.collectReachableObjects(new Set([tipId]), new Set()),
        ),
      );
      const packSize = packBytes.length;

      // Client repo (empty)
      const client = createMemoryHistoryWithOperations();
      await client.initialize();

      const channel = new MessageChannel();

      const start = performance.now();

      // Run server and client concurrently
      const [serveResult, fetchResult] = await Promise.all([
        messagePortServe(channel.port2, createRepoFacade(server), createRefStoreAdapter(server), {
          requestPolicy: "ANY",
        }),
        messagePortFetch(channel.port1, createRepoFacade(client), createRefStoreAdapter(client)),
      ]);

      const duration = performance.now() - start;
      const throughput = (packSize / duration) * 1000;

      console.log(`\n[E2E FETCH] MessagePort fetch:`);
      console.log(`  Pack size: ${formatBytes(packSize)}`);
      console.log(`  Duration: ${duration.toFixed(2)}ms`);
      console.log(`  Throughput: ${formatRate(throughput)}`);
      console.log(
        `  Server success: ${serveResult.success}${serveResult.error ? ` (${serveResult.error})` : ""}`,
      );
      console.log(
        `  Client success: ${fetchResult.success}${fetchResult.error ? ` (${fetchResult.error})` : ""}`,
      );

      expect(serveResult.success).toBe(true);
      expect(fetchResult.success).toBe(true);
      expect(throughput).toBeGreaterThan(1024 * 1024); // >1MB/sec

      channel.port1.close();
      channel.port2.close();
      await client.close();
      await server.close();
    });
  });

  // ─────────────────────────────────────────────────────────────────────────
  // 2. Latency Benchmarks
  // ─────────────────────────────────────────────────────────────────────────

  describe("2. Latency", () => {
    it("ref discovery completes in <100ms", { timeout: 5000 }, async () => {
      const server = createMemoryHistoryWithOperations();
      await server.initialize();

      // Create a repo with multiple branches
      let tip: string | undefined;
      for (let i = 0; i < 10; i++) {
        const blobId = await server.blobs.store([new TextEncoder().encode(`content-${i}`)]);
        const treeId = await server.trees.store([{ mode: 0o100644, name: "file.txt", id: blobId }]);
        tip = await server.commits.store({
          tree: treeId,
          parents: tip ? [tip] : [],
          author: createPerson(i),
          committer: createPerson(i),
          message: `Commit ${i}`,
        });
        await server.refs.set(`refs/heads/branch-${i}`, tip);
      }

      // Time ref listing (simulates server-side ref advertisement)
      const refStoreAdapter = createRefStoreAdapter(server);

      const start = performance.now();
      const refs = await refStoreAdapter.listAll();
      const refMap = new Map<string, string>();
      for (const [name, oid] of refs) {
        refMap.set(name, oid);
      }
      const duration = performance.now() - start;

      console.log(`\n[LATENCY] Ref discovery:`);
      console.log(`  Refs found: ${refMap.size}`);
      console.log(`  Duration: ${duration.toFixed(2)}ms`);

      expect(refMap.size).toBeGreaterThanOrEqual(10);
      expect(duration).toBeLessThan(100);

      await server.close();
    });

    it("negotiation for incremental fetch completes in <100ms", { timeout: 10000 }, async () => {
      const history = createMemoryHistoryWithOperations();
      await history.initialize();

      // Create base chain of 20 commits
      let baseId: string | undefined;
      for (let i = 0; i < 20; i++) {
        const blobId = await history.blobs.store([new TextEncoder().encode(`base-${i}`)]);
        const treeId = await history.trees.store([
          { mode: 0o100644, name: "file.txt", id: blobId },
        ]);
        baseId = await history.commits.store({
          tree: treeId,
          parents: baseId ? [baseId] : [],
          author: createPerson(i),
          committer: createPerson(i),
          message: `Base ${i}`,
        });
      }

      // Add 5 new commits
      let tipId = baseId!;
      for (let i = 20; i < 25; i++) {
        const blobId = await history.blobs.store([new TextEncoder().encode(`new-${i}`)]);
        const treeId = await history.trees.store([
          { mode: 0o100644, name: "file.txt", id: blobId },
        ]);
        tipId = await history.commits.store({
          tree: treeId,
          parents: [tipId],
          author: createPerson(i),
          committer: createPerson(i),
          message: `New ${i}`,
        });
      }

      // Time the object graph traversal (negotiation equivalent)
      const start = performance.now();
      const objects: string[] = [];
      for await (const id of history.collectReachableObjects(
        new Set([tipId]),
        new Set([baseId!]),
      )) {
        objects.push(id);
      }
      const duration = performance.now() - start;

      console.log(`\n[LATENCY] Negotiation (incremental object discovery):`);
      console.log(`  New objects: ${objects.length}`);
      console.log(`  Duration: ${duration.toFixed(2)}ms`);

      // 5 new commits → 5 blobs + 5 trees + 5 commits = 15 objects
      expect(objects.length).toBeGreaterThanOrEqual(15);
      expect(duration).toBeLessThan(100);

      await history.close();
    });
  });

  // ─────────────────────────────────────────────────────────────────────────
  // 3. Memory Benchmarks
  // ─────────────────────────────────────────────────────────────────────────

  describe("3. Memory", () => {
    it("heap overhead stays under 50MB during large transfer", { timeout: 60000 }, async () => {
      // Force GC if available
      if (global.gc) global.gc();
      const heapBefore = process.memoryUsage().heapUsed;

      const server = createMemoryHistoryWithOperations();
      await server.initialize();

      // Create ~5MB of data (25 commits × 200KB blobs)
      const tipId = await createLargeRepo(server, 25, 200 * 1024);

      // Export pack
      const packBytes = await collectBytes(
        server.serialization.createPack(
          server.collectReachableObjects(new Set([tipId]), new Set()),
        ),
      );

      // Import into fresh repo
      const client = createMemoryHistoryWithOperations();
      await client.initialize();
      await client.serialization.importPack(toAsyncIterable(packBytes));

      const heapAfter = process.memoryUsage().heapUsed;
      const heapDelta = heapAfter - heapBefore;

      console.log(`\n[MEMORY] Heap usage during ~5MB transfer:`);
      console.log(`  Heap before: ${formatBytes(heapBefore)}`);
      console.log(`  Heap after: ${formatBytes(heapAfter)}`);
      console.log(`  Heap delta: ${formatBytes(heapDelta)}`);
      console.log(`  Pack size: ${formatBytes(packBytes.length)}`);

      // Heap overhead should be under 50MB
      // Note: in-memory stores hold all data, so overhead includes stored objects
      expect(heapDelta).toBeLessThan(50 * 1024 * 1024);

      await client.close();
      await server.close();
    });

    it("heap stabilizes after repeated transfers (no leak)", { timeout: 60000 }, async () => {
      if (global.gc) global.gc();

      const heapSamples: number[] = [];
      const iterations = 5;

      for (let iter = 0; iter < iterations; iter++) {
        const history = createMemoryHistoryWithOperations();
        await history.initialize();

        // Create small repo (5 commits × 50KB)
        const tipId = await createLargeRepo(history, 5, 50 * 1024);

        // Pack round-trip
        const pack = await collectBytes(
          history.serialization.createPack(
            history.collectReachableObjects(new Set([tipId]), new Set()),
          ),
        );

        const target = createMemoryHistoryWithOperations();
        await target.initialize();
        await target.serialization.importPack(toAsyncIterable(pack));

        await target.close();
        await history.close();

        if (global.gc) global.gc();
        heapSamples.push(process.memoryUsage().heapUsed);
      }

      // Check that heap doesn't grow unboundedly
      // Compare last sample to first — allow 20% growth for GC variance
      const firstSample = heapSamples[0];
      const lastSample = heapSamples[heapSamples.length - 1];
      const growth = (lastSample - firstSample) / firstSample;

      console.log(`\n[MEMORY] Leak detection (${iterations} iterations):`);
      console.log(`  Heap samples: ${heapSamples.map(formatBytes).join(" → ")}`);
      console.log(`  Growth: ${(growth * 100).toFixed(1)}%`);

      // Allow generous growth since GC is not deterministic without --expose-gc
      expect(growth).toBeLessThan(1.0); // <100% growth

      // Heap should not grow linearly — check that last half doesn't grow faster
      if (heapSamples.length >= 4) {
        const midpoint = Math.floor(heapSamples.length / 2);
        const firstHalfGrowth = heapSamples[midpoint] - heapSamples[0];
        const secondHalfGrowth = heapSamples[heapSamples.length - 1] - heapSamples[midpoint];
        console.log(
          `  First half growth: ${formatBytes(firstHalfGrowth)}, Second half: ${formatBytes(secondHalfGrowth)}`,
        );
      }
    });
  });

  // ─────────────────────────────────────────────────────────────────────────
  // 4. Concurrency Benchmarks
  // ─────────────────────────────────────────────────────────────────────────

  describe("4. Concurrency", () => {
    it("10 concurrent pack operations scale near-linearly", { timeout: 120000 }, async () => {
      // Create a shared source repo
      const source = createMemoryHistoryWithOperations();
      await source.initialize();
      const tipId = await createLargeRepo(source, 10, 50 * 1024);

      // Pre-create the pack to remove serialization variance
      const packBytes = await collectBytes(
        source.serialization.createPack(
          source.collectReachableObjects(new Set([tipId]), new Set()),
        ),
      );

      // Baseline: single import
      const singleStart = performance.now();
      {
        const target = createMemoryHistoryWithOperations();
        await target.initialize();
        await target.serialization.importPack(toAsyncIterable(packBytes));
        await target.close();
      }
      const singleDuration = performance.now() - singleStart;

      // Concurrent: 10 parallel imports
      const concurrentCount = 10;
      const concurrentStart = performance.now();
      await Promise.all(
        Array.from({ length: concurrentCount }, async () => {
          const target = createMemoryHistoryWithOperations();
          await target.initialize();
          await target.serialization.importPack(toAsyncIterable(packBytes));
          await target.close();
        }),
      );
      const concurrentDuration = performance.now() - concurrentStart;

      const scalingFactor = concurrentDuration / singleDuration;
      const efficiency = concurrentCount / scalingFactor;

      console.log(`\n[CONCURRENCY] Pack import scaling:`);
      console.log(`  Single import: ${singleDuration.toFixed(2)}ms`);
      console.log(`  ${concurrentCount} concurrent: ${concurrentDuration.toFixed(2)}ms`);
      console.log(`  Scaling factor: ${scalingFactor.toFixed(2)}x (ideal: ${concurrentCount}x)`);
      console.log(`  Efficiency: ${(efficiency * 100).toFixed(1)}%`);
      console.log(`  Pack size: ${formatBytes(packBytes.length)}`);

      // Concurrent should not be more than 5x slower than ideal linear scaling
      // (in single-threaded JS, concurrent async ops share the event loop)
      expect(scalingFactor).toBeLessThan(concurrentCount * 5);

      await source.close();
    });

    it(
      "concurrent MessagePort duplex transfers complete correctly",
      { timeout: 30000 },
      async () => {
        const { createMessagePortDuplex } = await import(
          "../src/adapters/messageport/messageport-duplex.js"
        );

        const concurrentCount = 10;
        const chunkSize = 16 * 1024; // 16KB chunks
        const chunkCount = 8; // 8 × 16KB = 128KB per transfer
        const dataSize = chunkSize * chunkCount;

        const start = performance.now();

        const results = await Promise.all(
          Array.from({ length: concurrentCount }, async () => {
            const channel = new MessageChannel();
            const duplex1 = createMessagePortDuplex(channel.port1);
            const duplex2 = createMessagePortDuplex(channel.port2);

            const receivedChunks: Uint8Array[] = [];
            const receivePromise = (async () => {
              for await (const chunk of duplex2) {
                receivedChunks.push(chunk);
                if (receivedChunks.length >= chunkCount) break;
              }
            })();

            for (let i = 0; i < chunkCount; i++) {
              duplex1.write(createRandomContent(chunkSize));
            }

            await receivePromise;
            await duplex1.close();
            channel.port1.close();
            channel.port2.close();

            return receivedChunks.reduce((sum, c) => sum + c.length, 0);
          }),
        );

        const duration = performance.now() - start;
        const totalTransferred = results.reduce((sum, r) => sum + r, 0);

        console.log(`\n[CONCURRENCY] Concurrent MessagePort transfers:`);
        console.log(`  Transfers: ${concurrentCount}`);
        console.log(`  Total data: ${formatBytes(totalTransferred)}`);
        console.log(`  Duration: ${duration.toFixed(2)}ms`);
        console.log(`  Throughput: ${formatRate((totalTransferred / duration) * 1000)}`);

        // All transfers should complete with correct data size
        for (const received of results) {
          expect(received).toBe(dataSize);
        }
      },
    );
  });

  // ─────────────────────────────────────────────────────────────────────────
  // 5. Incremental Sync Performance
  // ─────────────────────────────────────────────────────────────────────────

  describe("5. Incremental sync", () => {
    it(
      "incremental pack is proportionally smaller than full pack",
      { timeout: 30000 },
      async () => {
        const history = createMemoryHistoryWithOperations();
        await history.initialize();

        // Create base chain of 20 commits with 100KB blobs
        let baseId: string | undefined;
        for (let i = 0; i < 20; i++) {
          baseId = await createCommitWithBlob(history, 100 * 1024, i, baseId);
        }

        // Full pack
        const fullPackStart = performance.now();
        const fullPack = await collectBytes(
          history.serialization.createPack(
            history.collectReachableObjects(new Set([baseId!]), new Set()),
          ),
        );
        const fullPackDuration = performance.now() - fullPackStart;

        // Add 5 more commits
        let tipId = baseId!;
        for (let i = 20; i < 25; i++) {
          tipId = await createCommitWithBlob(history, 100 * 1024, i, tipId);
        }

        // Incremental pack (only new objects)
        const incrPackStart = performance.now();
        const incrPack = await collectBytes(
          history.serialization.createPack(
            history.collectReachableObjects(new Set([tipId]), new Set([baseId!])),
          ),
        );
        const incrPackDuration = performance.now() - incrPackStart;

        const ratio = incrPack.length / fullPack.length;

        console.log(`\n[INCREMENTAL] Pack size comparison:`);
        console.log(
          `  Full pack: ${formatBytes(fullPack.length)} in ${fullPackDuration.toFixed(2)}ms`,
        );
        console.log(
          `  Incremental pack: ${formatBytes(incrPack.length)} in ${incrPackDuration.toFixed(2)}ms`,
        );
        console.log(`  Size ratio: ${(ratio * 100).toFixed(1)}%`);

        // Incremental pack should be roughly proportional (5/25 = 20% ± overhead)
        expect(ratio).toBeLessThan(0.5); // Less than 50% of full pack
        expect(incrPackDuration).toBeLessThan(fullPackDuration); // Faster too

        await history.close();
      },
    );
  });
});
